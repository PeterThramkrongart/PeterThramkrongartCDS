[
  {"id":"benoit_spacyr_2020","abstract":"An R wrapper to the 'Python' 'spaCy' 'NLP' library, from <http://spacy.io>.","accessed":{"date-parts":[[2020,12,31]]},"author":[{"family":"Benoit","given":"Kenneth"},{"family":"Matsuo","given":"Akitaka"},{"family":"Council  (ERC-2011-StG 283794-QUANTESS)","given":"European Research"}],"issued":{"date-parts":[[2020,3,4]]},"source":"R-Packages","title":"spacyr: Wrapper to the 'spaCy' 'NLP' Library","title-short":"spacyr","type":"book","URL":"https://CRAN.R-project.org/package=spacyr","version":"1.2.1"},
  {"id":"blei_latent_2003","abstract":"We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.","author":[{"family":"Blei","given":"David M."},{"family":"Ng","given":"Andrew Y."},{"family":"Jordan","given":"Michael I."}],"container-title":"The Journal of Machine Learning Research","container-title-short":"J. Mach. Learn. Res.","ISSN":"1532-4435","issue":"null","issued":{"date-parts":[[2003,3,1]]},"page":"993–1022","source":"3/1/2003","title":"Latent dirichlet allocation","type":"article-journal","volume":"3"},
  {"id":"dowle_datatable_2020","author":[{"family":"Dowle","given":"Matt"},{"family":"Srinivasan","given":"Arun"}],"genre":"manual","issued":{"date-parts":[[2020]]},"title":"data.table: Extension of `data.frame`","type":"report","URL":"https://CRAN.R-project.org/package=data.table"},
  {"id":"honnibal_spacy_2020","author":[{"family":"Honnibal","given":"Matthew"},{"family":"Montani","given":"Ines"},{"family":"Van Landeghem","given":"Sofie"},{"family":"Boyd","given":"Adriane"}],"DOI":"10.5281/zenodo.1212303","issued":{"date-parts":[[2020]]},"publisher":"Zenodo","title":"spaCy: Industrial-strength Natural Language Processing in Python","type":"book","URL":"https://doi.org/10.5281/zenodo.1212303"},
  {"id":"hornik_opennlp_2019","author":[{"family":"Hornik","given":"Kurt"}],"genre":"manual","issued":{"date-parts":[[2019]]},"title":"openNLP: Apache OpenNLP tools interface","type":"report","URL":"https://CRAN.R-project.org/package=openNLP"},
  {"id":"jelodar_latent_2019","abstract":"Topic modeling is one of the most powerful techniques in text mining for data mining, latent data discovery, and finding relationships among data and text documents. Researchers have published many articles in the field of topic modeling and applied in various fields such as software engineering, political science, medical and linguistic science, etc. There are various methods for topic modelling; Latent Dirichlet Allocation (LDA) is one of the most popular in this field. Researchers have proposed various models based on the LDA in topic modeling. According to previous work, this paper will be very useful and valuable for introducing LDA approaches in topic modeling. In this paper, we investigated highly scholarly articles (between 2003 to 2016) related to topic modeling based on LDA to discover the research development, current trends and intellectual structure of topic modeling. In addition, we summarize challenges and introduce famous tools and datasets in topic modeling based on LDA.","accessed":{"date-parts":[[2020,12,19]]},"author":[{"family":"Jelodar","given":"Hamed"},{"family":"Wang","given":"Yongli"},{"family":"Yuan","given":"Chi"},{"family":"Feng","given":"Xia"},{"family":"Jiang","given":"Xiahui"},{"family":"Li","given":"Yanchao"},{"family":"Zhao","given":"Liang"}],"container-title":"Multimedia Tools and Applications","container-title-short":"Multimed Tools Appl","DOI":"10.1007/s11042-018-6894-4","ISSN":"1573-7721","issue":"11","issued":{"date-parts":[[2019,6,1]]},"language":"en","page":"15169-15211","source":"Springer Link","title":"Latent Dirichlet allocation (LDA) and topic modeling: models, applications, a survey","title-short":"Latent Dirichlet allocation (LDA) and topic modeling","type":"article-journal","URL":"https://doi.org/10.1007/s11042-018-6894-4","volume":"78"},
  {"id":"mullen_fast_2018","author":[{"family":"Mullen","given":"Lincoln A."},{"family":"Benoit","given":"Kenneth"},{"family":"Keyes","given":"Os"},{"family":"Selivanov","given":"Dmitry"},{"family":"Arnold","given":"Jeffrey"}],"container-title":"Journal of Open Source Software","DOI":"10.21105/joss.00655","issue":"23","issued":{"date-parts":[[2018]]},"page":"655","title":"Fast, consistent tokenization of natural language text","type":"article-journal","URL":"https://doi.org/10.21105/joss.00655","volume":"3"},
  {"id":"openNLP","author":[{"literal":"Apache Software Foundation"}],"issued":{"date-parts":[[2014]]},"title":"openNLP natural language processing library","type":"article-journal","URL":"http://opennlp.apache.org/"},
  {"id":"queiroz_tidytext_2020","abstract":"Using tidy data principles can make many text mining tasks easier, more effective, and consistent with tools already in wide use. Much of the infrastructure needed for text mining with tidy data frames already exists in packages like 'dplyr', 'broom', 'tidyr', and 'ggplot2'. In this package, we provide functions and supporting data sets to allow conversion of text to and from tidy formats, and to switch seamlessly between tidy tools and existing text mining packages.","accessed":{"date-parts":[[2020,12,30]]},"author":[{"family":"Queiroz","given":"Gabriela De"},{"family":"Fay","given":"Colin"},{"family":"Hvitfeldt","given":"Emil"},{"family":"Keyes","given":"Os"},{"family":"Misra","given":"Kanishka"},{"family":"Mastny","given":"Tim"},{"family":"Erickson","given":"Jeff"},{"family":"Robinson","given":"David"},{"family":"Silge  [aut","given":"Julia"},{"family":"cre","given":""}],"issued":{"date-parts":[[2020,9,20]]},"source":"R-Packages","title":"tidytext: Text Mining using 'dplyr', 'ggplot2', and Other Tidy Tools","title-short":"tidytext","type":"book","URL":"https://CRAN.R-project.org/package=tidytext","version":"0.2.6"},
  {"id":"r_core_team_r_2017","author":[{"literal":"R Core Team"}],"event-place":"Vienna, Austria","issued":{"date-parts":[[2017]]},"publisher":"R Foundation for Statistical Computing","publisher-place":"Vienna, Austria","title":"R: A Language and Environment for Statistical Computing","type":"book","URL":"https://www.R-project.org/"},
  {"id":"rinker_textstem_2018","author":[{"family":"Rinker","given":"Tyler W."}],"event-place":"Buffalo, New York","genre":"manual","issued":{"date-parts":[[2018]]},"publisher-place":"Buffalo, New York","title":"textstem: Tools for stemming and lemmatizing text","type":"report","URL":"http://github.com/trinker/textstem"},
  {"id":"robinson_gutenbergr_2020","author":[{"family":"Robinson","given":"David"}],"genre":"manual","issued":{"date-parts":[[2020]]},"title":"gutenbergr: Download and process public domain works from project gutenberg","type":"report","URL":"https://CRAN.R-project.org/package=gutenbergr"},
  {"id":"rstudio_team_rstudio_2020","author":[{"literal":"RStudio Team"}],"event-place":"Boston, MA","issued":{"date-parts":[[2020]]},"publisher":"RStudio, PBC.","publisher-place":"Boston, MA","title":"RStudio: Integrated Development Environment for R","type":"book","URL":"http://www.rstudio.com/"},
  {"id":"selivanov_text2vec_2020-4","author":[{"family":"Selivanov","given":"Dmitriy"},{"family":"Bickel","given":"Manuel"},{"family":"Wang","given":"Qing"}],"genre":"manual","issued":{"date-parts":[[2020]]},"title":"text2vec: Modern text mining framework for r","type":"report","URL":"https://CRAN.R-project.org/package=text2vec"},
  {"id":"selivanov_topic_2018","accessed":{"date-parts":[[2020,12,4]]},"author":[{"family":"Selivanov","given":"Dmitriy"}],"issued":{"date-parts":[[2018,12,21]]},"title":"Topic modeling","type":"webpage","URL":"http://text2vec.org/topic_modeling.html"},
  {"id":"sievert_ldavis_2015","abstract":"Tools to create an interactive web-based visualization of a topic model that has been fit to a corpus of text data using Latent Dirichlet Allocation (LDA). Given the estimated parameters of the topic model, it computes various summary statistics as input to an interactive visualization built with D3.js that is accessed via a browser. The goal is to help users interpret the topics in their LDA topic model.","accessed":{"date-parts":[[2020,11,27]]},"author":[{"family":"Sievert","given":"Carson"},{"family":"Shirley","given":"Kenny"}],"issued":{"date-parts":[[2015,10,24]]},"source":"R-Packages","title":"LDAvis: Interactive Visualization of Topic Models","title-short":"LDAvis","type":"book","URL":"https://CRAN.R-project.org/package=LDAvis","version":"0.3.2"},
  {"id":"silge_text_2017","abstract":"Much of the data available today is unstructured and text-heavy, making it challenging for analysts to apply their usual data wrangling and visualization tools. With this practical book, youll explore text-mining techniques with tidytext, a package that authors Julia Silge and David Robinson developed using the tidy principles behind R packages like ggraph and dplyr. Youll learn how tidytext and other tidy tools in R can make text analysis easier and more effective. The authors demonstrate how treating text as data frames enables you to manipulate, summarize, and visualize characteristics of text. Youll also learn how to integrate natural language processing (NLP) into effective workflows. Practical code examples and data explorations will help you generate real insights from literature, news, and social media. Learn how to apply the tidy text format to NLPUse sentiment analysis to mine the emotional content of text Identify a documents most important terms with frequency measurements Explore relationships and connections between words with the ggraph and widyr packages Convert back and forth between Rs tidy and non-tidy text formatsUse topic modeling to classify document collections into natural groups Examine case studies that compare Twitter archives, dig into NASA metadata, and analyze thousands of Usenet messages","author":[{"family":"Silge","given":"Julia"},{"family":"Robinson","given":"David"}],"edition":"1st","ISBN":"978-1-4919-8165-8","issued":{"date-parts":[[2017]]},"number-of-pages":"194","publisher":"O'Reilly Media, Inc.","source":"ACM Digital Library","title":"Text Mining with R: A Tidy Approach","title-short":"Text Mining with R","type":"book"},
  {"id":"urbanek_rjava_2020","author":[{"family":"Urbanek","given":"Simon"}],"genre":"manual","issued":{"date-parts":[[2020]]},"title":"rJava: Low-level r to java interface","type":"report","URL":"https://CRAN.R-project.org/package=rJava"},
  {"id":"ushey_reticulate_2020","author":[{"family":"Ushey","given":"Kevin"},{"family":"Allaire","given":"JJ"},{"family":"Tang","given":"Yuan"}],"genre":"manual","issued":{"date-parts":[[2020]]},"title":"reticulate: Interface to 'python'","type":"report","URL":"https://CRAN.R-project.org/package=reticulate"},
  {"id":"wickham_tidy_2014-1","accessed":{"date-parts":[[2019,1,2]]},"author":[{"family":"Wickham","given":"Hadley"}],"container-title":"Journal of Statistical Software","DOI":"10.18637/jss.v059.i10","ISSN":"1548-7660","issue":"1","issued":{"date-parts":[[2014,9,12]]},"language":"en","page":"1-23","source":"www.jstatsoft.org","title":"Tidy Data","type":"article-journal","URL":"https://www.jstatsoft.org/index.php/jss/article/view/v059i10","volume":"59"},
  {"id":"wickham_welcome_2019","author":[{"family":"Wickham","given":"Hadley"},{"family":"Averick","given":"Mara"},{"family":"Bryan","given":"Jennifer"},{"family":"Chang","given":"Winston"},{"family":"McGowan","given":"Lucy D'Agostino"},{"family":"François","given":"Romain"},{"family":"Grolemund","given":"Garrett"},{"family":"Hayes","given":"Alex"},{"family":"Henry","given":"Lionel"},{"family":"Hester","given":"Jim"},{"family":"Kuhn","given":"Max"},{"family":"Pedersen","given":"Thomas Lin"},{"family":"Miller","given":"Evan"},{"family":"Bache","given":"Stephan Milton"},{"family":"Müller","given":"Kirill"},{"family":"Ooms","given":"Jeroen"},{"family":"Robinson","given":"David"},{"family":"Seidel","given":"Dana Paige"},{"family":"Spinu","given":"Vitalie"},{"family":"Takahashi","given":"Kohske"},{"family":"Vaughan","given":"Davis"},{"family":"Wilke","given":"Claus"},{"family":"Woo","given":"Kara"},{"family":"Yutani","given":"Hiroaki"}],"container-title":"Journal of Open Source Software","DOI":"10.21105/joss.01686","issue":"43","issued":{"date-parts":[[2019]]},"page":"1686","title":"Welcome to the tidyverse","type":"article-journal","volume":"4"},
  {"id":"wijffels_udpipe_2020","abstract":"This natural language processing toolkit provides language-agnostic 'tokenization', 'parts of speech tagging', 'lemmatization' and 'dependency parsing' of raw text. Next to text parsing, the package also allows you to train annotation models based on data of 'treebanks' in 'CoNLL-U' format as provided at <https://universaldependencies.org/format.html>. The techniques are explained in detail in the paper: 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', available at <doi:10.18653/v1/K17-3009>. The toolkit also contains functionalities for commonly used data manipulations on texts which are enriched with the output of the parser. Namely functionalities and algorithms for collocations, token co-occurrence, document term matrix handling, term frequency inverse document frequency calculations, information retrieval metrics (Okapi BM25), handling of multi-word expressions, keyword detection (Rapid Automatic Keyword Extraction, noun phrase extraction, syntactical patterns) sentiment scoring and semantic similarity analysis.","accessed":{"date-parts":[[2020,12,30]]},"author":[{"family":"Wijffels","given":"Jan"},{"family":"BNOSAC","given":""},{"family":"Linguistics","given":"Institute of Formal and Applied"},{"family":"Physics","given":"Faculty of Mathematics","dropping-particle":"and"},{"family":"Prague","given":"Charles University","dropping-particle":"in"},{"family":"Republic","given":"Czech"},{"family":"Straka","given":"Milan"},{"family":"Straková","given":"Jana"}],"issued":{"date-parts":[[2020,12,10]]},"source":"R-Packages","title":"udpipe: Tokenization, Parts of Speech Tagging, Lemmatization and Dependency Parsing with the 'UDPipe' 'NLP' Toolkit","title-short":"udpipe","type":"book","URL":"https://CRAN.R-project.org/package=udpipe","version":"0.8.5"},
  {"id":"wild_cran_2020","accessed":{"date-parts":[[2020,12,31]]},"author":[{"family":"Wild","given":"Fridolin"},{"family":"Lab (PAL)","given":"Performance Augmentation"},{"family":"University","given":"Oxford Brookes"},{"family":"UK","given":""}],"issued":{"date-parts":[[2020,12,9]]},"source":"cran.r-project.org","title":"CRAN Task View: Natural Language Processing","title-short":"CRAN Task View","type":"article-journal","URL":"https://CRAN.R-project.org/view=NaturalLanguageProcessing"}
]
